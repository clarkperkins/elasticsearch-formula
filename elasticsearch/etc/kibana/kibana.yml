{%- set local = 'elasticsearch.client' in grains.roles or 'elasticsearch.master' in grains.roles or 'elasticsearch.data' in grains.roles -%}
{%- set client_nodes = salt['mine.get']('G@stack_id:' ~ grains.stack_id ~ ' and G@roles:elasticsearch.client', 'grains.items', 'compound').values() -%}
{%- if local -%}
  {%- set es_host = 'localhost' -%}
{%- elif client_nodes -%}
  {%- set es_host = client_nodes[0].fqdn -%}
{%- else -%}
  {%- set master_nodes = salt['mine.get']('G@stack_id:' ~ grains.stack_id ~ ' and G@roles:elasticsearch.master', 'grains.items', 'compound').values() -%}
  {%- set es_host = master_nodes[0].fqdn -%}
{%- endif -%}
{%- set shield = salt['pillar.get']('elasticsearch:encrypted', False) -%}
# Kibana is served by a back end server. This controls which port to use.
# server.port: 5601

# The host to bind the server to.
# server.host: "0.0.0.0"

# If you are running kibana behind a proxy, and want to mount it at a path,
# specify that path here. The basePath can't end in a slash.
# server.basePath: ""

# The Elasticsearch instance to use for all your queries.
elasticsearch.url: "http{% if shield %}s{% endif %}://{{ es_host }}:{{ pillar.elasticsearch.http_port }}"

# preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false,
# then the host you use to connect to *this* Kibana instance will be sent.
# elasticsearch.preserveHost: true

# Kibana uses an index in Elasticsearch to store saved searches, visualizations
# and dashboards. It will create a new index if it doesn't already exist.
# kibana.index: ".kibana"

# The default application to load.
# kibana.defaultAppId: "discover"

{% if shield %}
# If your Elasticsearch is protected with basic auth, these are the user credentials
# used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana
# users will still need to authenticate with Elasticsearch (which is proxied through
# the Kibana server)
elasticsearch.username: "synthesys"
elasticsearch.password: "123456"

# SSL for outgoing requests from the Kibana Server to the browser (PEM formatted)
server.ssl.cert: /etc/elasticsearch/server.crt
server.ssl.key: /etc/elasticsearch/server.key

# Optional setting to validate that your Elasticsearch backend uses the same key files (PEM formatted)
elasticsearch.ssl.cert: /etc/elasticsearch/server.crt
elasticsearch.ssl.key: /etc/elasticsearch/server.key

# If you need to provide a CA certificate for your Elasticsearch instance, put
# the path of the pem file here.
# elasticsearch.ssl.ca: /path/to/your/CA.pem

# Set to false to have a complete disregard for the validity of the SSL
# certificate.

# TODO this doesn't work when it's true, so I'm leaving it as false for now
elasticsearch.ssl.verify: false
{% endif %}

# Time in milliseconds to wait for elasticsearch to respond to pings, defaults to
# request_timeout setting
# elasticsearch.pingTimeout: 1500

# Time in milliseconds to wait for responses from the back end or elasticsearch.
# This must be > 0
# elasticsearch.requestTimeout: 300000

# Time in milliseconds for Elasticsearch to wait for responses from shards.
# Set to 0 to disable.
# elasticsearch.shardTimeout: 0

# Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying
# elasticsearch.startupTimeout: 5000

# Set the path to where you would like the process id file to be created.
# pid.file: /var/run/kibana.pid

# If you would like to send the log output to a file you can set the path below.
# logging.dest: stdout

# Set this to true to suppress all logging output.
# logging.silent: false

# Set this to true to suppress all logging output except for error messages.
# logging.quiet: false

# Set this to true to log all events, including system usage information and all requests.
# logging.verbose: false