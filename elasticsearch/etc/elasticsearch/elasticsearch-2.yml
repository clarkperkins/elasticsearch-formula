{%- set client = 'elasticsearch.client' in grains.roles -%}

{# We can only be a master or data node if we're not a client node #}
{%- set master = 'elasticsearch.master' in grains.roles and not client -%}
{%- set data = 'elasticsearch.data' in grains.roles and not client -%}

{%- set shield = salt['pillar.get']('elasticsearch:encrypted', False) -%}

{# the lists of master & data nodes should NOT include client nodes #}
{%- set master_nodes = salt['mine.get']('G@stack_id:' ~ grains.stack_id ~ ' and G@roles:elasticsearch.master and not G@roles:elasticsearch.client', 'grains.items', 'compound').values() -%}
{%- set data_nodes = salt['mine.get']('G@stack_id:' ~ grains.stack_id ~ ' and G@roles:elasticsearch.data and not G@roles:elasticsearch.client', 'grains.items', 'compound').values() -%}

{%- set num_master_nodes = master_nodes | length -%}
{%- set num_data_nodes = data_nodes | length -%}

{%- set num_shards = (num_data_nodes / 2) | int -%}
{%- if num_shards < 5 -%}
    {%- set num_shards = 5 -%}
{%- endif -%}

{%- set num_replicas = salt['pillar.get']('elasticsearch:replicas', 2) -%}

# Naming
cluster.name: {{ grains.namespace }}
node.name: {{ grains.id }}
node.master: {{ master | lower }}
node.data: {{ data | lower }}
node.client: {{ client | lower }}

# Network settings
network.host: {{ grains.fqdn }}
http.port: {{ pillar.elasticsearch.http_port }}
transport.tcp.port: {{ pillar.elasticsearch.tcp_port }}

# Discovery - just use the master nodes & disable multicast
discovery.zen.ping.multicast.enabled: false
discovery.zen.minimum_master_nodes: {{ ((num_master_nodes / 2) + 1) | int }}
discovery.zen.ping.unicast.hosts:
  {% for node in master_nodes %}
  - {{ node.fqdn }}:{{ pillar.elasticsearch.tcp_port }}
  {% endfor %}

# Recovery settings - this should help A LOT when restarting clusters.
gateway.recover_after_time: 2m
gateway.recover_after_nodes: {{ (num_data_nodes * 0.85) | int }}

# Storage paths
path.data: /mnt/elasticsearch/data
path.logs: /mnt/elasticsearch/logs

# Disable the JVM from being swapped out
bootstrap.mlockall: true
bootstrap.memory_lock: true

{% if pillar.elasticsearch.marvel.install and pillar.elasticsearch.marvel.external_cluster %}
marvel.agent.exporters:
  id1:
    type: http
    host: ["http://{{ pillar.elasticsearch.marvel.external_cluster }}:{{ pillar.elasticsearch.http_port }}"]
{% endif %}

{% if pillar.elasticsearch.marvel.is_external %}
marvel.agent.enabled: false
{% endif %}

{% if shield %}
# Shield settings
shield:
  http.ssl: true
  http.ssl.client.auth: optional
  transport.ssl: true
  transport.ssl.client.auth: required
  ssl:
    keystore:
      path: /etc/elasticsearch/elasticsearch.keystore
      password: elasticsearch
      key_password: elasticsearch
    truststore:
      path: /etc/elasticsearch/elasticsearch.truststore
      password: elasticsearch
  authc:
    realms:
      native:
        type: native
        order: 0
      file:
        type: file
        order: 1
      pki:
        type: pki
        order: 2
{% endif %}

index:
  number_of_shards: {{ num_shards }}
  number_of_replicas: {{ num_replicas }}

threadpool:
  bulk:
    queue_size: 1000

{% if pillar.elasticsearch.aws.install %}
cloud:
  node:
    auto_attributes: true

  aws:
    region: {{ pillar.elasticsearch.aws.region }}

    {% if pillar.elasticsearch.aws.access_key %}
    access_key: {{ pillar.elasticsearch.aws.access_key }}
    secret_key: {{ pillar.elasticsearch.aws.secret_key }}
    {% endif %}

# Do routing based on the AZ
cluster.routing.allocation.awareness.attributes: aws_availability_zone
{% endif %}
